\chapter{Feature Extraction}
\label{chap:Feature Extraction}
Feature extraction is a method of enhancing the performance of classification algorithms. Through different algorithms data sets with a large feature space is reduced to a smaller feature space. Classification algorithms has fewer features to assess, but the information gain of each feature is significantly larger, depending on the application. For anomaly detection, feature extraction focuses on producing features that specifically divides anomalies from normal data. Feature extraction can also be implemented for the isolation of different failures, this however is not within the scope of this thesis and only feature extraction for anomalies is discussed.

%\subsection{Linear Regression}

\section{Local Outlier Factor}
\label{section:OutlierFactor}
Most algorithms for anomaly detection are based on a metric which accounts for the entire dataset~\cite{breunig2000lof}. However, many anomalies are identifiable in relation to the local neighbourhood of data points and not the overall dataset. Therefore, \cite{breunig2000lof} developed the local outlier factor (LOF) algorithm that provides a measure of a data point's "outlierness" within a subset of data points. This implies that a data point is not classified as an anomaly or not, but a local outlier factor is calculated to determine how much a data point is distantiated from it's $k$-nearest neighbours. This is clearly demonstrated in Figure~\ref{fig:localOutlierFactor} where the data points which are clustered together have smaller outlier scores than data points which are removed from the highly dense areas. The radious of the red circle around each data point is equivalent to the outlier score, $\mathbf{LOF}$.

\begin{figure}[!hbt]
	\centering
	\import{Figures/}{LOF.pgf}
	\caption{Local outlier factor of random data set to demonstrate the outlier score produced by the local outlier factor algorithm.}
	\label{fig:localOutlierFactor}
\end{figure}

To calculate the $\mathbf{LOF}$, the $k$-distance, $d_k$, must be calculated and also the local reachability density $\mathbf{LRD}$. The $d_k$, is the $k^{th}$ ranked $d(p_o,p_i)$. Where $d(p_o,p_i)$ is the distance between data point $p_o$ and any data point $p_i$, with $i \in N$, where $N$ is the number of data points within the dataset with a minimum value of $N_{min}$. The minimum data points for a data point, $p_o$, is a function of the minimum value of points and denoted as $N_{min}(d_o)$. To reduce fluctuations in the $d(p_o,p_i)$ the distance between $p_o$ and $p_i$ is replaced with 
\begin{equation}
\textbf{max} \left( d(p_o,p_i), d_k \right),
\end{equation}
and will henceforth be referred to as the reachability distance, $\mathbf{d}$, ~\cite{breunig2000lof}. The $\mathbf{LRD}$ of a data point, $p_o$, is calculated as 
\begin{equation}
\mathbf{LRD}_{N_{min}}(p_o) = 1/\left(\frac{\sum\limits_{p_i \in N_{min}(p_o)}^{} \mathbf{d}_{N_{min}}(p_o,p_i)}{\left|N_{min}(p_o) \right|}\right),
\label{Eq-lrd}
\end{equation}
and denotes "the inverse of the average reachability distance based on the $N_{min}$-nearest neighbours of the $p_o$"~\cite{breunig2000lof}. Eq~\ref{Eq-lrd} enables the calculation for the $\mathbf{LOF}$ of point $p_o$ given as
\begin{equation}
\mathbf{LOF}_{N_{min}}(p_o) = \frac{\sum\limits_{p_i \in N_{min}(p_o)}^{}\frac{\mathbf{LRD}_{N_{min}}(p_i)}{\mathbf{LRD}_{N_{min}}(p_o)}}{\left| N_{min}(p_o) \right|}.
\label{Eq-LOF}
\end{equation}
The rule of thumb for detecting an outlier is that when the LOF is larger than $2$, then the point is considered an outlier with respect to its neighbourhood. This however is not fixed and the threshold can be changed depending on the application. LOF can therefore also be a anomaly detection algorithm if a given threshold is implemented otherwise the $\mathbf{LOF}$ can be given as an additional feature for other anomaly detection algorithms.

This method is aimed at producing a measure of the "outlierness" of a data point within a local neighbourhood and not for all the data points. This method will thus be implemented for the satellite anomaly detection, since it will detect anomalies within the two neighbourhoods produced by the eclipse during orbit. This method will also be able to detect anomalies from measurements of the nadir sensor, sun sensor and magnetometers that drastically change from the training data set. 

\subsection{Analysis}
\textbf{TODO: Subtract 1 from the plots}
To demonstrate the LOF during anomalies the LOF is trained on a normal operation of the satellite simulation without any anomalies. Thereafter, the LOF for both the sun reflection anomaly as well as the magnetic moment disturbance is provided in Figure~\ref{fig:reflectionLOF} and Figure~\ref{fig:solarPanelDipoleLOF} respectively. The timesteps when the anomaly occurs are given a red background.

In Figure~\ref{fig:reflectionLOF} is evident that the LOF increases after the sun reflection anomaly occurs. The LOF decreases at a steady pace after the increase of the LOF to a peak. It is clear that the LOF is stable at a value of $1$ if no anomaly occurred within $\pm 1000$ s.

\begin{figure}[!htb]
	\centering
	
	\import{Figures/TexFigures/FeatureExtraction-LOF/Predictor-None/Isolator-None/Recovery-None/EARTH_SUN-ORC-General CubeSat Model/Reflection/}{LOF.pgf}
	
	\caption{Local outlier factor during first 2 orbits. The red area is when the sun reflection anomaly occurs}
	\label{fig:reflectionLOF}
\end{figure}

In Figure~\ref{fig:solarPanelDipoleLOF} the same pattern as Figure~\ref{fig:reflectionLOF} occurs, where the stable value of the LOF without any anomalies is $1$. Figure~\ref{fig:solarPanelDipoleLOF} demonstrates this even more clearly, since the value increases significantly after an anomaly occurs and decreases to a value of $1$ after the anomaly period is over. From both Figure~\ref{fig:reflectionLOF} and Figure~\ref{fig:solarPanelDipoleLOF} it is clear that an anomaly will be detected shortly after the anomaly occurs, if using the threshold for LOF of $2$. It however decreases during the magnetic moment disturbance anomaly, but this will not have a significant effect if the anomaly is detected and recovered from. The only purpose of the feature extraction method is to provide a feature that increases the information gain of whether a data sample is a anomaly or not and it is clear that the LOF does this.

\begin{figure}[!htb]
	\centering
	
	\import{Figures/TexFigures/FeatureExtraction-LOF/Predictor-None/Isolator-None/Recovery-None/EARTH_SUN-ORC-General CubeSat Model/solarPanelDipole/}{LOF.pgf}
	
	\caption{Local outlier factor during first 2 orbits. The red area is when the magnetic moment disturbance occurs}
	\label{fig:solarPanelDipoleLOF}
\end{figure}

It also important to note that the LOF also provides a severity of the anomaly, This is evident in that the LOF for the sun reflection reaches a maximum of $16$, while the maximum for the magnetic moment disturbance is $12$. This is even with a large duration in which the magnetic moment disturbance occurs, while the sun reflection does not occur frequently. This is expected when comparing the estimation metric during the sun reflection and the estimation metric during the magnetic disturbance in Figure~\ref{fig:reflectionEstimation} and Figure~\ref{fig:solarPanelDipoleOnEstimation}.


\section{Linear Regression Model}
The proposed method by \cite{DeSilva2020} uses Dynamic Mode Decomposition (DMD), which was initially developed by \cite{schmid2011applications} and further expanded to include control by \cite{proctor2016dynamic}, to provide an estimation of a sensor vector based on the previous measurement of the sensor as well as the measurements of the other sensors in the system. DMD was first developed in the fluids community and constructed a matrix $\mathbf{A}$ to relate the state vector $x$ with the following time step of the state vector, $x_{k+1}$. The state vector, in our case, will be the measurement vector of the specific sensor that we want to monitor.
\begin{equation}
	\mathbf{x}_{k+1} = \mathbf{Ax}_k
\end{equation}
Where $\mathbf{x}_k$ and $\mathbf{x}_{k+1}$ during a specified number of time steps, will be denoted as $\mathbf{X}$ and $\mathbf{X'}$ respectively.

The method of DMD, however, is useful for high order systems where the calculation of $\mathbf{A}$ is computationally intensive. This is not the case for our system, and using DMD is not justifiable and consequently, a linear regression model is implemented. Therefore with the pseudo-inverse of $\mathbf{X}$, denoted as $\mathbf{X^{\dagger}}$, we calculate $\mathbf{A}$ as
\begin{equation}
	\mathbf{A} = \mathbf{X}\mathbf{X^{\dagger}}
\end{equation}
This necessitates data of the state vector over time. The article by \cite{DeSilva2020} however includes $\mathbf{B}$ to relate the vector measurements of the other sensors to adjust the predicted state, $X_{k+1}$ of the monitored sensor. 
\begin{equation}
	\mathbf{X}_{k+1} = \mathbf{AX}_k + \mathbf{BY}_k
	\label{control DMD}
\end{equation}
Where $\mathbf{Y}_k$ is the other sensor measurements, this is adjusted for our use case, where $\mathbf{Y}_k$ is the control torques for the magnetorquers and reaction wheels, while $\mathbf{X}_k$ is all of the sensor measurements. Consequently, the model of Eq~\ref{control DMD} denotes the prediction of the sensor measurements at time step $k+1$ based on the current sensor measurements and control inputs.
Thereafter, as implemented by \cite{DeSilva2020} the model is adjusted with a Kalman Filter. From $\mathbf{A}$ and $\mathbf{B}$ the Kalman filter can be implemented to predict $\mathbf{X}_{k+1}$
\begin{equation}
	\hat{\mathbf{X}}_{k+1} = \mathbf{A}\hat{\mathbf{X}}_k + \mathbf{B}\mathbf{Y}_k + K(\mathbf{X}_k - \hat{\mathbf{X}}_k)
\end{equation}
where $K = 0.001$. After the calculation of $\hat{\mathbf{X}}_{k+1}$ \cite{DeSilva2020} proposes a moving average of the innovation covariance
\begin{equation}
	\mathbf{V}_k = \frac{1}{N} \sum_{i=k-N}^k (\mathbf{X}_i - \hat{\mathbf{X}}_i)(\mathbf{X}_i - \hat{\mathbf{X}}_i)^T
\end{equation}
where $N$ is the number of timesteps to account for. The moving average is used as an additional input parameter for the classification of anomalies based on $\mathbf{X}$.

\subsection{Analysis}
The moving average provided by the linear regression method is a matrix and therefore it is difficult to visualize whether the method provides a feature that provides information gain. This can however be simplified to a summation of the absolute values in the moving average (SAVMA) to demonstrate the increase of the values within the matrix after an anomaly occurs. Since the moving average has, by definition, a delayed response to the anomaly, it is expected that the SAVMA will respond as shown in Figure~\ref{fig:reflectionDMD} and Figure~\ref{fig:solarPanelDipoleDMD}. In the case of the sun reflection the SAVMA increases after an anomaly occurs. The SAVMA however has a delayed response in returning to a normal stable value, which would be $0$ if there were perfect conditions.

\begin{figure}[!htb]
	\centering
	
	\import{Figures/TexFigures/FeatureExtraction-DMD/Predictor-None/Isolator-None/Recovery-None/EARTH_SUN-ORC-General CubeSat Model/Reflection/}{DMD.pgf}
	
	\caption{Summation of absolute values in the moving average during first 2 orbits. The red area is when the sun reflection anomaly occurs}
	\label{fig:reflectionDMD}
\end{figure}

\begin{figure}[!htb]
	\centering
	
	\import{Figures/TexFigures/FeatureExtraction-DMD/Predictor-None/Isolator-None/Recovery-None/EARTH_SUN-ORC-General CubeSat Model/solarPanelDipole/}{DMD.pgf}
	
	\caption{Summation of absolute values in the moving average during first 2 orbits. The red area is when the  magnetic moment disturbance occurs}
	\label{fig:solarPanelDipoleDMD}
\end{figure}

In Figure~\ref{fig:solarPanelDipoleDMD} there does not seem to be any different between the anomalous and normal periods. The moving average provides the change in the relationship between the control input and the sensors. Figure~\ref{fig:solarPanelDipoleDMD} provides us with the insight that the magnetic moment disturbance has a smaller effect on the relationship between the sensor and the control input when compared to that of the sun reflection. This also correlates with the comparison of the LOF for sun reflection and magnetic moment disturbance.

\section{Summary}
The feature extraction methods discussed in this chapter focuses on extracting features that provide information gain on whether a data point is an anomaly or not. For the LOF algorithm this is done by providing a value for the "outlierness" of that data point relative to its nearest neighbourhood~\cite{breunig2000lof}. The linear regression model is an adaptation of work by \cite{DeSilva2020} to provides an estimate of the sensor measurements based on the previous sensor measurements as well as the control inputs. This can be extended to calculate a moving average of the estimated sensor measurements and the actual sensor measurements.